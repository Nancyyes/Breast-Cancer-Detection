{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing our cancer dataset\ndataset = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\nX = dataset.iloc[:, 2:32].values\nY = dataset.iloc[:, 1].values","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n        1.189e-01],\n       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n        8.902e-02],\n       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n        8.758e-02],\n       ...,\n       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n        7.820e-02],\n       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n        1.240e-01],\n       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n        7.039e-02]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head\nprint(\"Cancer data set dimensions : {}\".format(dataset.shape))  # find the dataset dimensions\n","execution_count":50,"outputs":[{"output_type":"stream","text":"Cancer data set dimensions : (569, 33)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 means the cancer is malignant and 0 means benign. \ndataset.isnull().sum()\ndataset.isna().sum() # check NA and NULL","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"id                           0\ndiagnosis                    0\nradius_mean                  0\ntexture_mean                 0\nperimeter_mean               0\narea_mean                    0\nsmoothness_mean              0\ncompactness_mean             0\nconcavity_mean               0\nconcave points_mean          0\nsymmetry_mean                0\nfractal_dimension_mean       0\nradius_se                    0\ntexture_se                   0\nperimeter_se                 0\narea_se                      0\nsmoothness_se                0\ncompactness_se               0\nconcavity_se                 0\nconcave points_se            0\nsymmetry_se                  0\nfractal_dimension_se         0\nradius_worst                 0\ntexture_worst                0\nperimeter_worst              0\narea_worst                   0\nsmoothness_worst             0\ncompactness_worst            0\nconcavity_worst              0\nconcave points_worst         0\nsymmetry_worst               0\nfractal_dimension_worst      0\nUnnamed: 32                569\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Phase 2 — Categorical Data\nWe will use Label Encoder to label the categorical dat\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlaberlencoder_Y = LabelEncoder()\nY = laberlencoder_Y.fit_transform(Y)","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 20)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train\nX_test","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"array([[1.071e+01, 2.039e+01, 6.950e+01, ..., 8.600e-02, 2.605e-01,\n        8.701e-02],\n       [1.561e+01, 1.938e+01, 1.000e+02, ..., 8.568e-02, 2.683e-01,\n        6.829e-02],\n       [1.863e+01, 2.511e+01, 1.248e+02, ..., 1.848e-01, 3.444e-01,\n        9.782e-02],\n       ...,\n       [1.371e+01, 2.083e+01, 9.020e+01, ..., 1.556e-01, 3.196e-01,\n        1.151e-01],\n       [1.174e+01, 1.402e+01, 7.424e+01, ..., 8.290e-02, 3.101e-01,\n        6.688e-02],\n       [1.200e+01, 1.565e+01, 7.695e+01, ..., 7.632e-02, 3.379e-01,\n        7.924e-02]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Phase 3 — Feature Scaling\n bring all features to the same level of magnitudes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":53,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Phase 4 — Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Logistic Regression Algorithm to the Training Set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 20)\nclassifier.fit(X_train, Y_train)\n\n# Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, Y_train)\n\n#Using SVC method of svm class to use Support Vector Machine Algorithm\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 20)\nclassifier.fit(X_train, Y_train)\n\n#Using SVC method of svm class to use Kernel SVM Algorithm\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 20)\nclassifier.fit(X_train, Y_train)\n\n#Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, Y_train)\n\n#Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 20)\nclassifier.fit(X_train, Y_train)\n\n#Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 20)\nclassifier.fit(X_train, Y_train)","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=20)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = classifier.predict(X_test)","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"array(['B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'B',\n       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'M',\n       'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'M',\n       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'M',\n       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B',\n       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M',\n       'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n       'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B',\n       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test, Y_pred)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm","execution_count":64,"outputs":[{"output_type":"execute_result","execution_count":64,"data":{"text/plain":"array([[83,  3],\n       [ 7, 50]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Classification Accuracy is what we usually mean, when we use the term accuracy. It is the ratio of number of correct predictions to the total number of input samples."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}